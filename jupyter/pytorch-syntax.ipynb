{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "在开始介绍 pytorch 的一个使用语法结构前,我们先说一下 深度学习领域几位真正的大神,可以说深度学习领域的目前的产出都离不开这几位大神\n",
    "Hinton, LeCun, Bengio\n",
    "\n",
    "Hinton 杰弗里·埃弗里斯特·辛顿\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Geoffrey_Hinton_at_UBC.jpg/440px-Geoffrey_Hinton_at_UBC.jpg\" style=\"zoom:50%;margin-left:0px\" />\n",
    "\n",
    "杰弗里·埃弗里斯特·辛顿 FRS（英语：Geoffrey Everest Hinton）（1947年12月6日－）是一位英国出生的加拿大计算机学家和心理学家，以其在神经网络方面的贡献闻名。辛顿是反向传播算法和对比散度算法的发明人之一，也是深度学习的积极推动者\n",
    "\n",
    "后面两位就不细说了,总之都是很牛,可以说这三位以及他们的学生 点亮了深度学习领域的一盏明灯\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch 基础及重要 api 介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先 推荐优先使用虚拟环境,接下来我们准备安装依赖包 \n",
    "\n",
    "```\n",
    "pip3 install http://download.pytorch.org/whl/torch-0.3.1-cp36-cp36m-macosx_10_7_x86_64.whl \n",
    "pip3 install torchvision \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor 张量\n",
    "Pytorch 里面的基本对象就是张量 Tensor, 其表示的是已给多维的矩阵,其和 numpy 的数组是对应的 Tensor ,二者的区别就是 Pytorch 的 Tensor 可以运行在 GPU 上, TensorFlow 的 tensor 也是\n",
    "\n",
    "依据数据类型 tensor 分一下几种\n",
    "- torch.FloatTensor 32\n",
    "- torch.DoubleTensor 64\n",
    "- torch.shortTensor 16\n",
    "- torch.IntTensor 32\n",
    "\n",
    "下面我们给一些实例说明演示一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2  3\n",
      " 4  8\n",
      " 7  9\n",
      "[torch.FloatTensor of size 3x2]\n",
      "\n",
      "a size is torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.FloatTensor([[2,3], [4,8], [7,9]])\n",
    "print(\"{}\".format(a))\n",
    "print(\"a size is {}\".format(a.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero tensor:\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 3x2]\n",
      "\n",
      "randn init the tensor:\n",
      "-1.4649  0.4602\n",
      "-0.0587 -0.3246\n",
      "-0.4576  0.5864\n",
      "[torch.FloatTensor of size 3x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#使用 torch 创建全是 0 的张量\n",
    "c = torch.zeros((3,2))\n",
    "print(\"zero tensor:{}\".format(c))\n",
    "\n",
    "#随机初始化指定矩阵\n",
    "d = torch.randn((3,2))\n",
    "print(\"randn init the tensor:{}\".format(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conver to numpy is \n",
      " [[-1.46490312  0.46020213]\n",
      " [-0.05871292 -0.32455546]\n",
      " [-0.45758563  0.58635259]]\n",
      "the torch_e is : \n",
      " 2  3\n",
      " 4  5\n",
      "[torch.LongTensor of size 2x2]\n",
      "\n",
      "the torch_e change data type is : \n",
      " 2  3\n",
      " 4  5\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#与 numpy 互转\n",
    "numpy_b = d.numpy()\n",
    "print(\"conver to numpy is \\n {}\".format(numpy_b))\n",
    "#np array conver to tensor\n",
    "e = np.array([[2, 3], [4, 5]])\n",
    "torch_e = torch.from_numpy(e)\n",
    "print(\"the torch_e is : {}\".format(torch_e))\n",
    "print(\"the torch_e change data type is : {}\".format(torch_e.float()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable \n",
    "变量的本质其实和张量相同,只不过 torch 当中的变量可以自动求导,不过变量不会被放入计算图中, torch 的变量实在 torch.autograd.Variable 中 将一个 tensor 变成 Variable 很简单 只需要 Variable(a) 就可以了\n",
    "> Variable 包含三个比较重要的组成属性: ***data*** , ***grad*** , ***grad_fn*** 通过 data 可以取出变量里面的张量数值, grad_fn 是计算梯度的操作,比如是通过加减还是乘除得来的,最后 grad 是反向传播的梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 2\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "x = Variable(torch.Tensor([1]), requires_grad = True)\n",
    "w = Variable(torch.Tensor([2]), requires_grad = True)\n",
    "b = Variable(torch.Tensor([3]), requires_grad = True)\n",
    "# Build a computational graph\n",
    "y = w * x + b   # y = 2 * x +3\n",
    "\n",
    "y.backward()\n",
    "\n",
    "print(x.grad)    # x.grad = 2\n",
    "print(w.grad)    # w.grad = 1\n",
    "print(b.grad)    # b.grad = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:Variable containing:\n",
      "-3.3103\n",
      " 1.2091\n",
      "-0.7545\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "Variable containing:\n",
      " 2.0000\n",
      " 0.2000\n",
      " 0.0200\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 除了上面针对标量求导以外,我们还可以针对矩阵求导\n",
    "x = torch.randn(3)\n",
    "x = Variable(x, requires_grad=True)\n",
    "y = x * 2\n",
    "print(\"y:{}\".format(y))\n",
    "y.backward(torch.FloatTensor([1, 0.1, 0.01]))\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据集\n",
    "在处理任何机器学习问题之前都需要数据读取,并进行预处理. Pytorch 提供了很多工具使得数据的读取和预处理变得很容易.\n",
    "\n",
    "torch.utils.data.DataSet 是代表这一数据的抽象类,你可以自己定义你的数据类继承 和 重写 这个抽象类, 你可以自己定义你的数据类继承 和重写这个抽象类,非常简单, 只需要定义 ***_ _len_ _*** ,***_ _getitem_ _*** 这两个列表,例如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "class MyDataSet(Dataset):\n",
    "    def __init__(self, csv_file, txt_file, root_dir, other_file):\n",
    "        self.csv_file = csv_file\n",
    "        with open(txt_file,'r') as f:\n",
    "            data_list = f.readlines()\n",
    "        self.txt_data = data_list\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.csv_file)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = txt_data[idx]\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 批量迭代可以使用 \n",
    "#dataiter = DataLoader(MyDataSet, batch_size=32, shuffle=True, collate_fn=default_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模组 nn.Module\n",
    "在 pyTorch 里面编写神经网络,所有的层结构 和损失函数都来自于 torch.nn, 所有的模型都从这个基类继承而来  nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "class net_name(torch.nn.Module):\n",
    "    def __init__(self, other_arguments):\n",
    "        super(\"net_name\", self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=None, out_channels=None, kernel_size=3)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型的加载和保存\n",
    "在 PyTorch里面使用 ***torch.save***来保存模型的结构和参数，有两种保存方式: \n",
    "- 保存整个模型的结构信息和参数信息，保存的对象是模型 model; \n",
    "- 保存模型的参数，保存的对象是模型的状态 model.state_dict() 可以这样保存， savc 的第 个参数是保存对象，第二个参数是保存路径及名称:\n",
    "```torch.save(model , 'model.pth')``` \n",
    "```torch.save(model.state_dict(),'model_state.pth')```\n",
    "\n",
    "加载模型有两种方式对应于保存模型的方式: \n",
    "- 加载完整的模型结构和参数信息，使用 loadmodel = torch.load('model.pth' ) ，在网络较大的时候加载的时间比较长，同时存储空间也比较大; -- 加载模型参数信息，需要先导人模型的结构，然后通过 model.load_state_dic(torch.load('model state.pth')) 来导入\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 基于 pytorch 的一些简单应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性模型:通常就是给定很多个数据点,希望能够找到一个函数来拟合这些数据点,并使其误差最小,比如最简单的一元线性模型可以用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_train = np.array([[3.3], [4.4], [5.5], [6.71], [6.93], [4.168], \n",
    "                  [9.779], [6.182], [7.59], [2.167], [7.042], \n",
    "                  [10.791], [5.313], [7.997], [3.1]], dtype=np.float32)\n",
    "\n",
    "y_train = np.array([[1.7], [2.76 ], [2.09], [3.19], [1.694], \n",
    "                     [1.573], [3.366], [2.596], [2.53], [1.221], [2.827],\n",
    "                     [3.465], [1.65], [2.904], [1.3]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAELCAYAAADdriHjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nakoSEZEABYOIiAQoGEREJEDBICIiAf8fFW328/PkqdUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1)#就在图表1中画图！\n",
    "#\n",
    "#plt1=plt.subplot(2,1,1)\n",
    "T = np.arctan2(x_train,y_train) # for color value\n",
    "# 散点图\n",
    "plt.scatter(x_train, y_train, s=75, c=T, alpha=.5)\n",
    "# 线图\n",
    "#plt.plot(y_train,x_train,'.-')\n",
    "plt.xlabel('x_train')\n",
    "plt.xlim(0,10)\n",
    "plt.ylim(0.00,10)\n",
    "plt.ylabel('y_tain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(1,1) #输入输出定义都是1维\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = LinearRegression().cuda()\n",
    "else:\n",
    "    model = LinearRegression()\n",
    "    \n",
    "criterion = torch.nn.MSELoss() #定义均方差损失函数\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)#定义优化函数,这里使用梯度下降\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:19999/1000000 loss:0.1689153015613556 \n",
      "Epoch:39999/1000000 loss:0.1689152717590332 \n",
      "Epoch:59999/1000000 loss:0.1689152717590332 \n",
      "Epoch:79999/1000000 loss:0.168915256857872 \n",
      "Epoch:99999/1000000 loss:0.168915256857872 \n",
      "Epoch:119999/1000000 loss:0.168915256857872 \n",
      "Epoch:139999/1000000 loss:0.1689152866601944 \n",
      "Epoch:159999/1000000 loss:0.16891522705554962 \n",
      "Epoch:179999/1000000 loss:0.1689152866601944 \n",
      "Epoch:199999/1000000 loss:0.1689152866601944 \n",
      "Epoch:219999/1000000 loss:0.16891522705554962 \n",
      "Epoch:239999/1000000 loss:0.1689152866601944 \n",
      "Epoch:259999/1000000 loss:0.16891522705554962 \n",
      "Epoch:279999/1000000 loss:0.168915256857872 \n",
      "Epoch:299999/1000000 loss:0.1689152717590332 \n",
      "Epoch:319999/1000000 loss:0.16891524195671082 \n",
      "Epoch:339999/1000000 loss:0.168915256857872 \n",
      "Epoch:359999/1000000 loss:0.1689152717590332 \n",
      "Epoch:379999/1000000 loss:0.16891522705554962 \n",
      "Epoch:399999/1000000 loss:0.1689152866601944 \n",
      "Epoch:419999/1000000 loss:0.16891521215438843 \n",
      "Epoch:439999/1000000 loss:0.168915256857872 \n",
      "Epoch:459999/1000000 loss:0.1689152717590332 \n",
      "Epoch:479999/1000000 loss:0.168915256857872 \n",
      "Epoch:499999/1000000 loss:0.168915256857872 \n",
      "Epoch:519999/1000000 loss:0.16891522705554962 \n",
      "Epoch:539999/1000000 loss:0.16891524195671082 \n",
      "Epoch:559999/1000000 loss:0.168915256857872 \n",
      "Epoch:579999/1000000 loss:0.1689152717590332 \n",
      "Epoch:599999/1000000 loss:0.16891524195671082 \n",
      "Epoch:619999/1000000 loss:0.16891524195671082 \n",
      "Epoch:639999/1000000 loss:0.16891524195671082 \n",
      "Epoch:659999/1000000 loss:0.16891522705554962 \n",
      "Epoch:679999/1000000 loss:0.168915256857872 \n",
      "Epoch:699999/1000000 loss:0.168915256857872 \n",
      "Epoch:719999/1000000 loss:0.16891524195671082 \n",
      "Epoch:739999/1000000 loss:0.1689152866601944 \n",
      "Epoch:759999/1000000 loss:0.16891524195671082 \n",
      "Epoch:779999/1000000 loss:0.1689152866601944 \n",
      "Epoch:799999/1000000 loss:0.1689152866601944 \n",
      "Epoch:819999/1000000 loss:0.168915256857872 \n",
      "Epoch:839999/1000000 loss:0.16891522705554962 \n",
      "Epoch:859999/1000000 loss:0.16891524195671082 \n",
      "Epoch:879999/1000000 loss:0.1689152866601944 \n",
      "Epoch:899999/1000000 loss:0.1689152866601944 \n",
      "Epoch:919999/1000000 loss:0.168915256857872 \n",
      "Epoch:939999/1000000 loss:0.168915256857872 \n",
      "Epoch:959999/1000000 loss:0.168915256857872 \n",
      "Epoch:979999/1000000 loss:0.1689152866601944 \n",
      "Epoch:999999/1000000 loss:0.16891524195671082 \n"
     ]
    }
   ],
   "source": [
    "#接下来我们开始训练我们的模型\n",
    "from torch.autograd import Variable\n",
    "num_epochs = 1000000\n",
    "for epoch in range(num_epochs):\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = Variable(torch.from_numpy(x_train)).cuda()\n",
    "        target = Variable(torch.from_numpy(y_train)).cuda()\n",
    "    else:\n",
    "        inputs = Variable(torch.from_numpy(x_train))\n",
    "        target = Variable(torch.from_numpy(y_train))\n",
    "    # forward the forward gen the output\n",
    "    out = model(inputs)\n",
    "    loss = criterion(out, target)\n",
    "    # backward\n",
    "    # 每次反向传播 都重新归零梯度 否则会梯度累加 造成不收敛\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1)%20000 ==0:\n",
    "        print(\"Epoch:{}/{} loss:{} \".format(epoch, num_epochs, loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLiISQAp3EZEA+v/vAa0IX61nWAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#做完训练之后我们简单预测一下结果\n",
    "#将模型变成测试模式,这是因为有一些层操作如 \n",
    "#Dropout 和 BatchNormalization 在训练和测试的时候是不一样的\n",
    "model.eval() \n",
    "predict = model(Variable(torch.from_numpy(x_train)))\n",
    "predict = predict.data.numpy()\n",
    "plt.figure(2)#就在图表1中画图！\n",
    "T = np.arctan2(y_train,x_train) # for color value\n",
    "# 散点图\n",
    "plt.scatter(x_train, y_train, s=75, c=T, alpha=.5)\n",
    "plt.plot(x_train, predict, label = 'Fitting Line')\n",
    "plt.xlabel=\"x\"\n",
    "plt.Ylabel=\"y\"\n",
    "plt.xlim(0,10)\n",
    "plt.ylim(0.00,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 多项式回归\n",
    "对于一般的线性回归,由于该函数拟合出来是一条直线,所以进度欠佳,我们可以考虑多项式回归,也就是提高每个属性的次数.而不再是使用一次去回归目标函数\n",
    "\n",
    "原理和线性回归是一样的,只不过这里用的是高次多项式,而不是简单的一次线性多项式\n",
    "我们这里设置参数方程\n",
    "    y= b + w1*xz + w2*x^2 + 2.4*x^3\n",
    "另外在 pytorch 里面使用 torch.cat() 来实现Tensor 的拼接,这里就不详细介绍了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分类问题\n",
    "    机器学习当中的监督学习主要分为回归问题和分类问题, 回归他希望预测的结果是连续的, 那么分类问题所所预测的结果就是离散的类别,他的输入可以是离散的,也可以是连续的  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 标准案例-手写数字图片识别\n",
    "\n",
    "MNIST 数据集是一个手写字体数据集，包含O 到9 这10 个数字，其中有55000 张\n",
    "训练集， 10000 张测试集.5000 张验证集，图片大小是28 x 28 的灰度罔，如图3.28所示\n",
    "\n",
    "首先我们构建神经网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n导入构建网络结构的包 nn  和 学习优化器包 optimm\\n导入基础变量\\n导入数据加载工具\\n导入可视化工具\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import  nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets,transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\"\"\"\n",
    "导入构建网络结构的包 nn  和 学习优化器包 optimm\n",
    "导入基础变量\n",
    "导入数据加载工具\n",
    "导入可视化工具\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义一些超参\n",
    "batch_size=64\n",
    "test_batch_size=1000\n",
    "epochs=10\n",
    "lr=0.01\n",
    "momentum=0.5\n",
    "no_cuda=True\n",
    "seed=1\n",
    "log_interval=10\n",
    "cuda=torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自动下载手写图片的训练数据\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=test_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们构建一个简单的卷积神经网络,首先我们介绍一下 pytorch 里面的conv2d\n",
    "`torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)`\n",
    "http://pytorch.org/docs/master/nn.html\n",
    "\n",
    "第一层卷积,将输入的 channel 放大10倍,主要 group 这里是指卷积任务怎么拆分,分几组,我们这里默认1 所有输入全部链接到输出\n",
    "第二层我们将input channel 10 放大道20,\n",
    "接下来我们添加 dropout 防止过拟合\n",
    "最后我们进行两次全连接\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #卷积后 h = [h+2*padding-dilation∗(kernel_size−1)−1]/stride + 1\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        #使用 dropout 防止过拟合\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model = Net()\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, size_average=False).data[0] # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    test()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "具体的 详细可执行代码可以参考 minist_cnn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cnn 卷积申请网络使用的一些简单总结\n",
    "\n",
    "- 输入数据体的尺寸是W1* H1* D1 \n",
    "- 4 个超参数:滤波器数量K ， 滤波器空间尺寸F ， 滑动步长S ， 零填充的数量P 即 D2=K \n",
    "- 输出数据体的尺寸为W2* H2* D2 ， 其中W2 = (w1+2P -F)/S+1 ， H2 = (H1+2P -F)/S+1\n",
    "- 由于参数共享，每个滤波器包含的权重数目为 F*F*D1 ，卷积层→共有 F*F*D1 * K 个权重weight 和 bias\n",
    "- 在输出体数据中，第d个深度切片( 空间尺寸是W2 X H2 ) ， 用第d 个滤波器和输入数据进行有效卷积运算的结果，再加上第d个偏置。\n",
    "- 对于卷积神经网络的一些届参数，常见的设置是F=3 ， S=1 ， P=1 ，\n",
    "- 多个小的滤波器组合要比一个大的滤波器更好,因为多个小的滤波器可以使用更少的参数并且每一个滤波器后面都可以添加激活函数,可以更好的表征图片\n",
    "\n",
    "#### 池化\n",
    "- 池化相对于卷积来说只是利用图片的不变性 使用简单的计算如最大特征 平均值 等进一步减少网络参数,减低计算复杂度\n",
    "- 除了最大值池化之外，还有一些其他的池化函数，比如平均池化，或者L2 范数池化。在实际中证明，在卷积层之间引人最大池化的效果是最好的，而平均池化一般放在卷积神经网络的最后一层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 神经网络结构查看\n",
    "直接使用 ```print(model)``` 可以查看神经网络结构\n",
    "Net(\n",
    "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
    "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
    "  (conv2_drop): Dropout2d(p=0.5)\n",
    "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
    "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
